{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOnw4RTHJMOMkvKFhI8Bg8Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aishukambar/Pneumonia-Detection-Using-Tranfer-Learning/blob/main/data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtgtyN3OtOJs"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6zc-osktV0l"
      },
      "source": [
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
        "!unzip \\*.zip && rm *.zip\n",
        "print(\"Completed data download.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqIGqLrvtdoE",
        "outputId": "deb7f4c3-db40-41a2-8a9e-4a6e3861075e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "shutil.rmtree('chest_xray/__MACOSX')\n",
        "shutil.rmtree('chest_xray/chest_xray')\n",
        "os.rename('chest_xray', 'data')\n",
        "print(\"Completed data management.\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Completed data management.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQEsw4_7yxen"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import paths\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.applications import VGG19\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD\n",
        "from keras.models import Model \n",
        "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
        "from keras.callbacks import EarlyStopping\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1TaB2Aky09x"
      },
      "source": [
        "img_width, img_height = 128, 128\n",
        "train_data_dir = \"data/train\"\n",
        "validation_data_dir = \"data/val\"\n",
        "test_data_dir = \"data/test\"\n",
        "NB = 2\n",
        "BS = 64\n",
        "EPOCHS = 10"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7HNwGK_y4Cu"
      },
      "source": [
        "TRAIN = len(list(paths.list_images(train_data_dir)))\n",
        "VAL = len(list(paths.list_images(validation_data_dir)))\n",
        "TEST = len(list(paths.list_images(test_data_dir)))\n",
        "\n",
        "trainAug = ImageDataGenerator(rescale = 1./255,\n",
        "                    fill_mode = \"nearest\")\n",
        "\n",
        "valAug = ImageDataGenerator(rescale = 1./255,\n",
        "                            fill_mode = \"nearest\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XNPenfey9g1",
        "outputId": "9ef1cbec-f64f-42a0-c2cc-1a438f126246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "trainGen = trainAug.flow_from_directory(\n",
        "                    train_data_dir,\n",
        "                    target_size = (img_height, img_width),\n",
        "                    batch_size = BS,\n",
        "                    shuffle = True,\n",
        "                    class_mode = \"categorical\")\n",
        "\n",
        "valGen = valAug.flow_from_directory(\n",
        "                    validation_data_dir,\n",
        "                    target_size = (img_height, img_width),\n",
        "                    batch_size = BS,\n",
        "                    shuffle = False,\n",
        "                    class_mode = \"categorical\")\n",
        "\n",
        "testGen = valAug.flow_from_directory(\n",
        "                    test_data_dir,\n",
        "                    target_size = (img_height, img_width),\n",
        "                    batch_size = BS,\n",
        "                    shuffle = False,\n",
        "                    class_mode = \"categorical\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5216 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9wugZOHxgVt"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import paths\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.applications import VGG19\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD\n",
        "from keras.models import Model \n",
        "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "# defining constants and variables\n",
        "img_width, img_height = 128, 128\n",
        "train_data_dir = \"data/train\"\n",
        "validation_data_dir = \"data/val\"\n",
        "test_data_dir = \"data/test\"\n",
        "NB = 2\n",
        "BS = 64\n",
        "EPOCHS = 1\n",
        "\n",
        "\n",
        "# creating train, validation and test data generators\n",
        "TRAIN = len(list(paths.list_images(train_data_dir)))\n",
        "VAL = len(list(paths.list_images(validation_data_dir)))\n",
        "TEST = len(list(paths.list_images(test_data_dir)))\n",
        "\n",
        "trainAug = ImageDataGenerator(rescale = 1./255,\n",
        "                    fill_mode = \"nearest\")\n",
        "\n",
        "valAug = ImageDataGenerator(rescale = 1./255,\n",
        "                            fill_mode = \"nearest\")\n",
        "\n",
        "trainGen = trainAug.flow_from_directory(\n",
        "                    train_data_dir,\n",
        "                    target_size = (img_height, img_width),\n",
        "                    batch_size = BS,\n",
        "                    shuffle = True,\n",
        "                    class_mode = \"categorical\")\n",
        "\n",
        "valGen = valAug.flow_from_directory(\n",
        "                    validation_data_dir,\n",
        "                    target_size = (img_height, img_width),\n",
        "                    batch_size = BS,\n",
        "                    shuffle = False,\n",
        "                    class_mode = \"categorical\")\n",
        "\n",
        "testGen = valAug.flow_from_directory(\n",
        "                    test_data_dir,\n",
        "                    target_size = (img_height, img_width),\n",
        "                    batch_size = BS,\n",
        "                    shuffle = False,\n",
        "                    class_mode = \"categorical\")\n",
        "\n",
        "\n",
        "# loading pre-trained model, training additional features and saving model\n",
        "base_model = VGG19(weights = \"imagenet\", include_top=False, \n",
        "                   input_shape = (img_width, img_height, 3))\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation = \"relu\")(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Dense(256, activation = \"relu\")(x)\n",
        "x = Dropout(0.2)(x)\n",
        "preds = Dense(NB, activation = \"softmax\")(x)\n",
        "\n",
        "model = Model(base_model.input, preds)\n",
        "\n",
        "for i,layer in enumerate(model.layers):\n",
        "    print(i,layer.name)\n",
        "\n",
        "for layer in model.layers[:16]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[16:]:\n",
        "    layer.trainable=True\n",
        "\n",
        "model.summary()\n",
        "\n",
        "early = EarlyStopping(monitor = 'val_acc', min_delta = 0, \n",
        "                      patience = 10, verbose= 1 , mode = 'auto')\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\", \n",
        "                    optimizer = SGD(lr=0.001, momentum=0.9), \n",
        "                    metrics=[\"accuracy\"])\n",
        "\n",
        "H = model.fit_generator(\n",
        "        trainGen,\n",
        "        epochs = EPOCHS,\n",
        "        validation_data = valGen)\n",
        "\n",
        "model.save('model.h5')\n",
        "\n",
        "\n",
        "# generating predictions using model\n",
        "testGen.reset()\n",
        "predictions = model.predict_generator(testGen, steps = (TEST // BS) + 1) \n",
        "predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "print(\"Test set accuracy: \" + \n",
        "      str(accuracy_score(testGen.classes, predictions, normalize=True) * 100) \n",
        "      + \"%\") \n",
        "\n",
        "print(classification_report(testGen.classes, predictions,\n",
        "                            target_names=testGen.class_indices.keys())) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo8lnOuQOybj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}